---
layout: post
title:  "What We Do"
date:   2019-02-10 14:27:57 -0400
tags:  
author: Joshua Vogelstein
---

This blog post is our attempt to characterize what we, at [NeuroData](https://neurodata.io/), do. All of our actions are motivated by our mission, `to understand and improve intelligences`; the motivation behind our approach is described in our [about page](https://neurodata.io/about/).  This post summarizes the bulk or our actual work, which can be divided into three complementary threads:
1. big data systems
2. statistics / machine learning / artificial intelligence
3. applications

### Big Data Systems

A big data system is a computational ecosystem, including hardware and software, design to support analysis of "big data", operationally defined as data too big to fit into a single machine's working memory.  The operations of any big data system include: storing, interfacing, pipelining, and visualizing. For each, standard/existing solutions, are inadequate for a variety of reasons.  We therefore build, extend, and deploy systems that generalize the functionality of existing systems to support scientific inquiry.  To be concrete, we developed the Open Connectome Project stack in 2011 to host the first ever big dataset in electron microscopy (from Davi Bock and Clay Read) [[1]](https://doi.org/10.1145/2484838.2484870).  As the data size and complexity increased, the development needs extended beyond our capabilities, so we began collaborating extensively with other teams, including scientists and engineers at [Google](https://ai.google/research/people/VirenJain), [Allen Institute for Brain Science](https://alleninstitute.org/what-we-do/brain-science/), and [Janelia Research Campus](https://www.janelia.org/).  This collaboration led to our exisiting open source, community developed computational ecosystem, described [here](https://www.nature.com/articles/s41592-018-0181-1). The core components of this work include [bossDB](https://www.biorxiv.org/content/10.1101/217745v1) for big data storage, [NDWebtools](https://github.com/neurodata/ndwebtools) for interfacing with the data, [neuroglancer](https://github.com/google/neuroglancer) for visualizing, and various pipelines for different modalities, including [ndmg](https://neurodata.io/ndmg/) for MRI and [reg](https://neurodata.io/reg/) for registration of multifarious data.  We continue to extend our collaboration network and ecosystem, to support an ever growing need for big data systems in brain sciences across scales and modalities, ranging from electron microscopy, to full clear brains, to human and non-human magnetic resonance imaging.



### Statistics / Machine Learning / Artificial Intelligence

Statistics, machine learning, and artificial intelligence are terms that describe complementary approaches to solving overlapping sets of problems.  Central to all of them is the existence of some data samples, and a question.  These approaches then build tools  designed to learn an answer to the question from the data.  First, raw data in neuroscience tends to be very high-dimensional
(e.g., images can be petabytes), exhibiting many nonlinear
relationships (e.g., the input/output function of a neuron).  To that
end, we have developed a number computational statistics tools for
such settings. This includes state of the art methods for
dimensionality reduction ([LOL](https://arxiv.org/abs/1709.01233)),
classification ([rerf](http://arxiv.org/abs/1506.03410)), clustering
([eclust](https://arxiv.org/abs/1710.09859)), and hypothesis testing
([mgc](https://elifesciences.org/articles/41690)).  Second, the
eventual representation of data of most interest to us is networks in
the brain, or connectomes. To that end, we have spent much of the last
10 years building foundational statistical estimators, theories, and
algorithms for modeling populations of networks with graph, vertex,
and edge attributes.  A  survey summarizing much of our work was
recently published in JMLR
([here](http://jmlr.org/papers/v18/17-448.html)).  We subsequently
developed a python package that implements all of our theoretical
developments (available [here](https://neurodata.io/graspy/)), and
wrote a review article on our approach to modeling connectomes, called
`connectal coding`, available
[here](https://doi.org/10.1016/j.conb.2019.04.005).


### Applications

The potential applications of our work are widespread.  We illustrate
a couple applications spanning our most relevant work, including model
(non-human) systems and  human variation.  First, we characterized
which sets of neurons were causally involved in which behaviors, in
larval Drosophila ([2](https://doi.org/10.1126/science.1250298)). This
led to an exploratory analysis of the mushroom body of the larval
Drosophila, which we describe in detail in a [technical
report](http://arxiv.org/abs/1705.03297), with further analysis
availabe in our [survey JMLR
paper](http://jmlr.org/papers/v18/17-448.html), and our [connectal
coding paper](https://doi.org/10.1016/j.conb.2019.04.005).  Second, to
characterize human variation, we developed a cloud pipeline for
estimation and analysis of human connectomes
[[3](https://doi.org/10.1093/gigascience/gix013)], and used it to
quantify variability present within and across individuals and studies
[[4](https://doi.org/10.1101/188706)].



